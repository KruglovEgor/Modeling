{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4204f1c0",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9420d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c2dfa",
   "metadata": {},
   "source": [
    "### Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Названия классов\n",
    "classes = ['футболка', 'брюки', 'свитер', 'платье', 'пальто', \n",
    "           'туфли', 'рубашка', 'кроссовки', 'сумка', 'ботинки']\n",
    "\n",
    "print(f\"Training set: {x_train.shape}\")\n",
    "print(f\"Test set: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a15391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация примеров\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(20):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(classes[y_train[i]], fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b812296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данных\n",
    "x_train_flat = x_train.reshape(60000, 784)\n",
    "x_test_flat = x_test.reshape(10000, 784)\n",
    "\n",
    "# Нормализация\n",
    "x_train_norm = x_train_flat / 255.0\n",
    "x_test_norm = x_test_flat / 255.0\n",
    "\n",
    "# One-hot encoding для меток\n",
    "y_train_cat = utils.to_categorical(y_train, 10)\n",
    "y_test_cat = utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Preprocessed training data: {x_train_norm.shape}\")\n",
    "print(f\"Preprocessed test data: {x_test_norm.shape}\")\n",
    "print(f\"Labels shape: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1a2f5",
   "metadata": {},
   "source": [
    "## 2. Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c77b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layers_config, input_dim=784, output_dim=10):\n",
    "    \"\"\"\n",
    "    Создает модель с заданной конфигурацией слоев\n",
    "    \n",
    "    Parameters:\n",
    "    layers_config: list - список с количеством нейронов в каждом слое\n",
    "    \n",
    "    Returns:\n",
    "    model: Sequential - скомпилированная модель\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Первый слой\n",
    "    model.add(Dense(layers_config[0], input_dim=input_dim, activation='relu'))\n",
    "    \n",
    "    # Скрытые слои (если есть)\n",
    "    for neurons in layers_config[1:]:\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    \n",
    "    # Выходной слой\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "    # Компиляция\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, x_train, y_train, x_test, y_test, \n",
    "                       epochs=20, batch_size=100, verbose=0):\n",
    "    \"\"\"\n",
    "    Обучает и оценивает модель\n",
    "    \n",
    "    Returns:\n",
    "    dict с результатами: history, test_loss, test_accuracy, params_count\n",
    "    \"\"\"\n",
    "    # Обучение\n",
    "    history = model.fit(x_train, y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=0.2,\n",
    "                       verbose=verbose)\n",
    "    \n",
    "    # Оценка на тестовых данных\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    # Подсчет параметров\n",
    "    params_count = model.count_params()\n",
    "    \n",
    "    return {\n",
    "        'history': history,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'params_count': params_count,\n",
    "        'train_accuracy': history.history['accuracy'][-1],\n",
    "        'val_accuracy': history.history['val_accuracy'][-1]\n",
    "    }\n",
    "\n",
    "def plot_history(history, title='Training History'):\n",
    "    \"\"\"\n",
    "    Визуализирует историю обучения\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Train')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title(f'{title} - Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Loss\n",
    "    ax2.plot(history.history['loss'], label='Train')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title(f'{title} - Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Вспомогательные функции готовы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b24a8c",
   "metadata": {},
   "source": [
    "## 3. Эксперимент 1: Количество нейронов на входном слое\n",
    "\n",
    "Тестируем: 400, 600, 800, 1200 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперимент 1: Входной слой\n",
    "input_layer_neurons = [400, 600, 800, 1200]\n",
    "exp1_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ 1: Количество нейронов на входном слое\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for neurons in input_layer_neurons:\n",
    "    print(f\"\\nОбучение модели с {neurons} нейронами на входном слое...\")\n",
    "    \n",
    "    model = create_model([neurons])\n",
    "    results = train_and_evaluate(model, x_train_norm, y_train_cat, \n",
    "                                x_test_norm, y_test_cat,\n",
    "                                epochs=20, batch_size=100, verbose=1)\n",
    "    \n",
    "    exp1_results.append({\n",
    "        'neurons': neurons,\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'val_accuracy': results['val_accuracy'],\n",
    "        'params': results['params_count'],\n",
    "        'history': results['history']\n",
    "    })\n",
    "    \n",
    "    print(f\"Точность на тесте: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Точность на валидации: {results['val_accuracy']:.4f}\")\n",
    "    print(f\"Параметры модели: {results['params_count']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbe57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение результатов Эксперимента 1\n",
    "df_exp1 = pd.DataFrame([{\n",
    "    'Нейроны': r['neurons'],\n",
    "    'Точность (тест)': f\"{r['test_accuracy']:.4f}\",\n",
    "    'Точность (вал)': f\"{r['val_accuracy']:.4f}\",\n",
    "    'Параметры': f\"{r['params']:,}\"\n",
    "} for r in exp1_results])\n",
    "\n",
    "print(\"\\nРезультаты Эксперимента 1:\")\n",
    "print(df_exp1.to_string(index=False))\n",
    "\n",
    "# Находим лучшую модель\n",
    "best_idx = np.argmax([r['test_accuracy'] for r in exp1_results])\n",
    "print(f\"\\nЛучшая конфигурация: {exp1_results[best_idx]['neurons']} нейронов\")\n",
    "print(f\"Точность: {exp1_results[best_idx]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация лучшей модели из Эксперимента 1\n",
    "plot_history(exp1_results[best_idx]['history'], \n",
    "            f\"Exp 1: {exp1_results[best_idx]['neurons']} neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26a06e",
   "metadata": {},
   "source": [
    "## 4. Эксперимент 2: Один скрытый слой\n",
    "\n",
    "Добавляем один скрытый слой: 200, 300, 400, 600, 800 нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперимент 2: Один скрытый слой\n",
    "hidden_layer_neurons = [200, 300, 400, 600, 800]\n",
    "exp2_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ 2: Добавление одного скрытого слоя\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Используем лучшую конфигурацию из Эксп. 1 для входного слоя\n",
    "best_input_neurons = exp1_results[best_idx]['neurons']\n",
    "\n",
    "for hidden_neurons in hidden_layer_neurons:\n",
    "    print(f\"\\nОбучение модели: [{best_input_neurons}, {hidden_neurons}]...\")\n",
    "    \n",
    "    model = create_model([best_input_neurons, hidden_neurons])\n",
    "    results = train_and_evaluate(model, x_train_norm, y_train_cat, \n",
    "                                x_test_norm, y_test_cat,\n",
    "                                epochs=20, batch_size=100, verbose=1)\n",
    "    \n",
    "    exp2_results.append({\n",
    "        'config': f\"{best_input_neurons}-{hidden_neurons}\",\n",
    "        'hidden_neurons': hidden_neurons,\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'val_accuracy': results['val_accuracy'],\n",
    "        'params': results['params_count'],\n",
    "        'history': results['history']\n",
    "    })\n",
    "    \n",
    "    print(f\"Точность на тесте: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Точность на валидации: {results['val_accuracy']:.4f}\")\n",
    "    print(f\"Параметры модели: {results['params_count']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение результатов Эксперимента 2\n",
    "df_exp2 = pd.DataFrame([{\n",
    "    'Конфигурация': r['config'],\n",
    "    'Точность (тест)': f\"{r['test_accuracy']:.4f}\",\n",
    "    'Точность (вал)': f\"{r['val_accuracy']:.4f}\",\n",
    "    'Параметры': f\"{r['params']:,}\"\n",
    "} for r in exp2_results])\n",
    "\n",
    "print(\"\\nРезультаты Эксперимента 2:\")\n",
    "print(df_exp2.to_string(index=False))\n",
    "\n",
    "# Находим лучшую модель\n",
    "best_idx2 = np.argmax([r['test_accuracy'] for r in exp2_results])\n",
    "print(f\"\\nЛучшая конфигурация: {exp2_results[best_idx2]['config']}\")\n",
    "print(f\"Точность: {exp2_results[best_idx2]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация лучшей модели из Эксперимента 2\n",
    "plot_history(exp2_results[best_idx2]['history'], \n",
    "            f\"Exp 2: {exp2_results[best_idx2]['config']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd82b1",
   "metadata": {},
   "source": [
    "## 5. Эксперимент 3: Несколько скрытых слоев\n",
    "\n",
    "Тестируем разные архитектуры с 2-3 скрытыми слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперимент 3: Несколько скрытых слоев\n",
    "multi_layer_configs = [\n",
    "    [800, 400, 200],\n",
    "    [800, 600, 400],\n",
    "    [1200, 600, 300],\n",
    "    [800, 400, 200, 100],\n",
    "    [1200, 800, 400, 200]\n",
    "]\n",
    "\n",
    "exp3_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ 3: Несколько скрытых слоев\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for config in multi_layer_configs:\n",
    "    config_str = '-'.join(map(str, config))\n",
    "    print(f\"\\nОбучение модели: {config_str}...\")\n",
    "    \n",
    "    model = create_model(config)\n",
    "    results = train_and_evaluate(model, x_train_norm, y_train_cat, \n",
    "                                x_test_norm, y_test_cat,\n",
    "                                epochs=20, batch_size=100, verbose=1)\n",
    "    \n",
    "    exp3_results.append({\n",
    "        'config': config_str,\n",
    "        'layers': len(config),\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'val_accuracy': results['val_accuracy'],\n",
    "        'params': results['params_count'],\n",
    "        'history': results['history']\n",
    "    })\n",
    "    \n",
    "    print(f\"Точность на тесте: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Точность на валидации: {results['val_accuracy']:.4f}\")\n",
    "    print(f\"Параметры модели: {results['params_count']:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение результатов Эксперимента 3\n",
    "df_exp3 = pd.DataFrame([{\n",
    "    'Конфигурация': r['config'],\n",
    "    'Слои': r['layers'],\n",
    "    'Точность (тест)': f\"{r['test_accuracy']:.4f}\",\n",
    "    'Точность (вал)': f\"{r['val_accuracy']:.4f}\",\n",
    "    'Параметры': f\"{r['params']:,}\"\n",
    "} for r in exp3_results])\n",
    "\n",
    "print(\"\\nРезультаты Эксперимента 3:\")\n",
    "print(df_exp3.to_string(index=False))\n",
    "\n",
    "# Находим лучшую модель\n",
    "best_idx3 = np.argmax([r['test_accuracy'] for r in exp3_results])\n",
    "print(f\"\\nЛучшая конфигурация: {exp3_results[best_idx3]['config']}\")\n",
    "print(f\"Точность: {exp3_results[best_idx3]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация лучшей модели из Эксперимента 3\n",
    "plot_history(exp3_results[best_idx3]['history'], \n",
    "            f\"Exp 3: {exp3_results[best_idx3]['config']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e06df",
   "metadata": {},
   "source": [
    "## 6. Эксперимент 4: Количество эпох\n",
    "\n",
    "Тестируем: 10, 15, 20, 25, 30 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперимент 4: Количество эпох\n",
    "epochs_list = [10, 15, 20, 25, 30]\n",
    "exp4_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ 4: Количество эпох\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Используем лучшую архитектуру из предыдущих экспериментов\n",
    "best_overall_idx = best_idx3\n",
    "best_config = multi_layer_configs[best_overall_idx]\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    print(f\"\\nОбучение модели с {epochs} эпохами...\")\n",
    "    \n",
    "    model = create_model(best_config)\n",
    "    results = train_and_evaluate(model, x_train_norm, y_train_cat, \n",
    "                                x_test_norm, y_test_cat,\n",
    "                                epochs=epochs, batch_size=100, verbose=1)\n",
    "    \n",
    "    exp4_results.append({\n",
    "        'epochs': epochs,\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'val_accuracy': results['val_accuracy'],\n",
    "        'train_accuracy': results['train_accuracy'],\n",
    "        'history': results['history']\n",
    "    })\n",
    "    \n",
    "    print(f\"Точность на тесте: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Точность на валидации: {results['val_accuracy']:.4f}\")\n",
    "    print(f\"Точность на обучении: {results['train_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение результатов Эксперимента 4\n",
    "df_exp4 = pd.DataFrame([{\n",
    "    'Эпохи': r['epochs'],\n",
    "    'Точность (тест)': f\"{r['test_accuracy']:.4f}\",\n",
    "    'Точность (вал)': f\"{r['val_accuracy']:.4f}\",\n",
    "    'Точность (обуч)': f\"{r['train_accuracy']:.4f}\",\n",
    "    'Переобучение': f\"{r['train_accuracy'] - r['val_accuracy']:.4f}\"\n",
    "} for r in exp4_results])\n",
    "\n",
    "print(\"\\nРезультаты Эксперимента 4:\")\n",
    "print(df_exp4.to_string(index=False))\n",
    "\n",
    "# Находим оптимальное количество эпох\n",
    "best_idx4 = np.argmax([r['test_accuracy'] for r in exp4_results])\n",
    "print(f\"\\nОптимальное количество эпох: {exp4_results[best_idx4]['epochs']}\")\n",
    "print(f\"Точность: {exp4_results[best_idx4]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403517d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация всех вариантов с разным количеством эпох\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, result in enumerate(exp4_results):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(result['history'].history['accuracy'], label='Train')\n",
    "    ax.plot(result['history'].history['val_accuracy'], label='Validation')\n",
    "    ax.set_title(f\"{result['epochs']} epochs\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Скрываем лишний subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493d12e",
   "metadata": {},
   "source": [
    "## 7. Эксперимент 5: Размер batch\n",
    "\n",
    "Тестируем: 10, 50, 100, 200, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эксперимент 5: Размер batch\n",
    "batch_sizes = [10, 50, 100, 200, 500]\n",
    "exp5_results = []\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ 5: Размер batch\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Используем лучшую конфигурацию и оптимальное количество эпох\n",
    "best_epochs = exp4_results[best_idx4]['epochs']\n",
    "\n",
    "import time\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nОбучение модели с batch_size={batch_size}...\")\n",
    "    \n",
    "    model = create_model(best_config)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = train_and_evaluate(model, x_train_norm, y_train_cat, \n",
    "                                x_test_norm, y_test_cat,\n",
    "                                epochs=best_epochs, batch_size=batch_size, verbose=1)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    exp5_results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'val_accuracy': results['val_accuracy'],\n",
    "        'training_time': training_time,\n",
    "        'history': results['history']\n",
    "    })\n",
    "    \n",
    "    print(f\"Точность на тесте: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Время обучения: {training_time:.2f} сек\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25189374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение результатов Эксперимента 5\n",
    "df_exp5 = pd.DataFrame([{\n",
    "    'Batch Size': r['batch_size'],\n",
    "    'Точность (тест)': f\"{r['test_accuracy']:.4f}\",\n",
    "    'Точность (вал)': f\"{r['val_accuracy']:.4f}\",\n",
    "    'Время (сек)': f\"{r['training_time']:.2f}\"\n",
    "} for r in exp5_results])\n",
    "\n",
    "print(\"\\nРезультаты Эксперимента 5:\")\n",
    "print(df_exp5.to_string(index=False))\n",
    "\n",
    "# Находим лучший batch_size\n",
    "best_idx5 = np.argmax([r['test_accuracy'] for r in exp5_results])\n",
    "print(f\"\\nОптимальный batch_size: {exp5_results[best_idx5]['batch_size']}\")\n",
    "print(f\"Точность: {exp5_results[best_idx5]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cce7f3",
   "metadata": {},
   "source": [
    "## 8. Анализ переобучения для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d72d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем лучшую модель с большим количеством эпох для анализа переобучения\n",
    "print(\"=\" * 80)\n",
    "print(\"АНАЛИЗ ПЕРЕОБУЧЕНИЯ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_batch_size = exp5_results[best_idx5]['batch_size']\n",
    "\n",
    "print(f\"\\nЛучшая конфигурация:\")\n",
    "print(f\"Архитектура: {'-'.join(map(str, best_config))}\")\n",
    "print(f\"Эпохи: {best_epochs}\")\n",
    "print(f\"Batch size: {best_batch_size}\")\n",
    "\n",
    "# Создаем финальную модель\n",
    "final_model = create_model(best_config)\n",
    "\n",
    "# Обучаем с расширенным количеством эпох для проверки переобучения\n",
    "final_history = final_model.fit(x_train_norm, y_train_cat,\n",
    "                               batch_size=best_batch_size,\n",
    "                               epochs=50,  # Увеличиваем для анализа\n",
    "                               validation_split=0.2,\n",
    "                               verbose=1)\n",
    "\n",
    "# Оценка\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test_norm, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nФинальная точность на тесте: {test_accuracy:.4f}\")\n",
    "print(f\"Финальная точность на валидации: {final_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Финальная точность на обучении: {final_history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация переобучения\n",
    "plot_history(final_history, \"Final Model - Overfitting Analysis (50 epochs)\")\n",
    "\n",
    "# Проверка на переобучение\n",
    "train_acc = final_history.history['accuracy'][-1]\n",
    "val_acc = final_history.history['val_accuracy'][-1]\n",
    "overfitting_gap = train_acc - val_acc\n",
    "\n",
    "print(f\"\\nРазница между train и validation accuracy: {overfitting_gap:.4f}\")\n",
    "if overfitting_gap > 0.05:\n",
    "    print(\"⚠️  Обнаружено переобучение! Разница > 5%\")\n",
    "else:\n",
    "    print(\"✓ Переобучение отсутствует или минимально\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводка модели\n",
    "print(\"\\nАрхитектура финальной модели:\")\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803aafd",
   "metadata": {},
   "source": [
    "## 9. Keras Tuner - Автоматический подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка Keras Tuner (если еще не установлен)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import keras_tuner as kt\n",
    "    print(f\"Keras Tuner уже установлен, версия: {kt.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Установка Keras Tuner...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"keras-tuner\", \"-q\"])\n",
    "    import keras_tuner as kt\n",
    "    print(f\"Keras Tuner установлен, версия: {kt.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели для Keras Tuner\n",
    "def build_tuner_model(hp):\n",
    "    \"\"\"\n",
    "    Функция построения модели для Keras Tuner\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Входной слой с настраиваемым количеством нейронов\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('input_units', min_value=400, max_value=1200, step=200),\n",
    "        activation='relu',\n",
    "        input_dim=784\n",
    "    ))\n",
    "    \n",
    "    # Настраиваемое количество скрытых слоев (1-3)\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=200, max_value=800, step=200),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "        # Опциональный Dropout\n",
    "        if hp.Boolean(f'dropout_{i}'):\n",
    "            model.add(Dropout(hp.Float(f'dropout_rate_{i}', 0.1, 0.5, step=0.1)))\n",
    "    \n",
    "    # Выходной слой\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Настраиваемый learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Функция построения модели для Keras Tuner готова!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и настройка тюнера\n",
    "print(\"=\" * 80)\n",
    "print(\"KERAS TUNER - Автоматический подбор гиперпараметров\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_tuner_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,\n",
    "    directory='kt_dir',\n",
    "    project_name='fashion_mnist_lab4',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "print(\"\\nПространство поиска:\")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск поиска\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "print(\"\\nЗапуск поиска оптимальных гиперпараметров...\")\n",
    "print(\"Это может занять некоторое время...\\n\")\n",
    "\n",
    "tuner.search(\n",
    "    x_train_norm, y_train_cat,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Поиск завершен!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение лучших гиперпараметров\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nЛучшие найденные гиперпараметры:\")\n",
    "print(f\"Входной слой: {best_hps.get('input_units')} нейронов\")\n",
    "print(f\"Количество скрытых слоев: {best_hps.get('num_layers')}\")\n",
    "\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    units = best_hps.get(f'units_{i}')\n",
    "    has_dropout = best_hps.get(f'dropout_{i}')\n",
    "    print(f\"  Слой {i+1}: {units} нейронов\", end=\"\")\n",
    "    if has_dropout:\n",
    "        dropout_rate = best_hps.get(f'dropout_rate_{i}')\n",
    "        print(f\", Dropout={dropout_rate}\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc562626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели с лучшими гиперпараметрами\n",
    "print(\"\\nОбучение модели с найденными гиперпараметрами...\\n\")\n",
    "\n",
    "tuned_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "tuned_history = tuned_model.fit(\n",
    "    x_train_norm, y_train_cat,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Оценка на тестовых данных\n",
    "tuned_test_loss, tuned_test_accuracy = tuned_model.evaluate(x_test_norm, y_test_cat, verbose=0)\n",
    "\n",
    "print(f\"\\nТочность модели Keras Tuner на тесте: {tuned_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e045cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация модели Keras Tuner\n",
    "plot_history(tuned_history, \"Keras Tuner - Best Model\")\n",
    "\n",
    "print(\"\\nАрхитектура модели Keras Tuner:\")\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ce298",
   "metadata": {},
   "source": [
    "## 10. Сравнение результатов: Ручной vs Автоматический подбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cca4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговое сравнение\n",
    "print(\"=\" * 80)\n",
    "print(\"ИТОГОВОЕ СРАВНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Подсчет параметров\n",
    "manual_params = final_model.count_params()\n",
    "tuned_params = tuned_model.count_params()\n",
    "\n",
    "comparison_data = {\n",
    "    'Метод': ['Ручной подбор', 'Keras Tuner'],\n",
    "    'Архитектура': [\n",
    "        '-'.join(map(str, best_config)),\n",
    "        f\"{best_hps.get('input_units')}-\" + '-'.join([str(best_hps.get(f'units_{i}')) for i in range(best_hps.get('num_layers'))])\n",
    "    ],\n",
    "    'Точность (тест)': [\n",
    "        f\"{test_accuracy:.4f}\",\n",
    "        f\"{tuned_test_accuracy:.4f}\"\n",
    "    ],\n",
    "    'Точность (вал)': [\n",
    "        f\"{final_history.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{tuned_history.history['val_accuracy'][-1]:.4f}\"\n",
    "    ],\n",
    "    'Параметры': [\n",
    "        f\"{manual_params:,}\",\n",
    "        f\"{tuned_params:,}\"\n",
    "    ],\n",
    "    'Эпохи': [\n",
    "        str(best_epochs),\n",
    "        str(len(tuned_history.history['accuracy']))\n",
    "    ],\n",
    "    'Batch Size': [\n",
    "        str(best_batch_size),\n",
    "        \"N/A\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", df_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa626b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# График точности\n",
    "methods = ['Ручной\\nподбор', 'Keras\\nTuner']\n",
    "accuracies = [test_accuracy, tuned_test_accuracy]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "axes[0].bar(methods, accuracies, color=colors, alpha=0.7)\n",
    "axes[0].set_ylabel('Точность на тесте')\n",
    "axes[0].set_title('Сравнение точности')\n",
    "axes[0].set_ylim([0.8, 0.95])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, (method, acc) in enumerate(zip(methods, accuracies)):\n",
    "    axes[0].text(i, acc + 0.005, f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# График размера модели\n",
    "params = [manual_params, tuned_params]\n",
    "\n",
    "axes[1].bar(methods, params, color=colors, alpha=0.7)\n",
    "axes[1].set_ylabel('Количество параметров')\n",
    "axes[1].set_title('Сравнение размера модели')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Добавляем значения на столбцы\n",
    "for i, (method, param) in enumerate(zip(methods, params)):\n",
    "    axes[1].text(i, param + max(params)*0.02, f'{param:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06428e0d",
   "metadata": {},
   "source": [
    "## 11. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06830fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ВЫВОДЫ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. ВЛИЯНИЕ КОЛИЧЕСТВА НЕЙРОНОВ НА ВХОДНОМ СЛОЕ:\")\n",
    "print(f\"   - Протестировано: {input_layer_neurons}\")\n",
    "print(f\"   - Лучший результат: {exp1_results[best_idx]['neurons']} нейронов\")\n",
    "print(f\"   - Точность: {exp1_results[best_idx]['test_accuracy']:.4f}\")\n",
    "print(\"   - Вывод: Увеличение нейронов улучшает точность до определенного предела\")\n",
    "\n",
    "print(\"\\n2. ВЛИЯНИЕ СКРЫТЫХ СЛОЕВ:\")\n",
    "print(f\"   - Добавление 1 скрытого слоя улучшило результат\")\n",
    "print(f\"   - Лучшая конфигурация с 1 слоем: {exp2_results[best_idx2]['config']}\")\n",
    "print(f\"   - Точность: {exp2_results[best_idx2]['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n3. МНОЖЕСТВЕННЫЕ СКРЫТЫЕ СЛОИ:\")\n",
    "print(f\"   - Лучшая архитектура: {exp3_results[best_idx3]['config']}\")\n",
    "print(f\"   - Точность: {exp3_results[best_idx3]['test_accuracy']:.4f}\")\n",
    "print(\"   - Вывод: Глубокие сети могут давать лучшие результаты, но требуют больше параметров\")\n",
    "\n",
    "print(\"\\n4. КОЛИЧЕСТВО ЭПОХ:\")\n",
    "print(f\"   - Оптимальное количество: {exp4_results[best_idx4]['epochs']} эпох\")\n",
    "print(f\"   - Переобучение начинается после {best_epochs} эпох\")\n",
    "print(f\"   - Разница train/val: {overfitting_gap:.4f}\")\n",
    "\n",
    "print(\"\\n5. РАЗМЕР BATCH:\")\n",
    "print(f\"   - Оптимальный batch_size: {exp5_results[best_idx5]['batch_size']}\")\n",
    "print(f\"   - Меньший batch дает лучшую точность, но медленнее обучается\")\n",
    "print(f\"   - Больший batch ускоряет обучение, но может снизить точность\")\n",
    "\n",
    "print(\"\\n6. СРАВНЕНИЕ РУЧНОГО И АВТОМАТИЧЕСКОГО ПОДБОРА:\")\n",
    "if test_accuracy > tuned_test_accuracy:\n",
    "    winner = \"Ручной подбор\"\n",
    "    diff = test_accuracy - tuned_test_accuracy\n",
    "else:\n",
    "    winner = \"Keras Tuner\"\n",
    "    diff = tuned_test_accuracy - test_accuracy\n",
    "\n",
    "print(f\"   - Победитель: {winner}\")\n",
    "print(f\"   - Разница в точности: {diff:.4f}\")\n",
    "print(f\"   - Ручной подбор: {test_accuracy:.4f} ({manual_params:,} параметров)\")\n",
    "print(f\"   - Keras Tuner: {tuned_test_accuracy:.4f} ({tuned_params:,} параметров)\")\n",
    "\n",
    "if manual_params < tuned_params:\n",
    "    print(f\"   - Ручная модель компактнее на {((tuned_params - manual_params) / tuned_params * 100):.1f}%\")\n",
    "else:\n",
    "    print(f\"   - Keras Tuner модель компактнее на {((manual_params - tuned_params) / manual_params * 100):.1f}%\")\n",
    "\n",
    "print(\"\\n7. ОБЩИЕ ВЫВОДЫ:\")\n",
    "print(\"   - Систематический ручной подбор может конкурировать с автоматическим\")\n",
    "print(\"   - Keras Tuner экономит время на эксперименты\")\n",
    "print(\"   - Важно контролировать переобучение независимо от метода подбора\")\n",
    "print(\"   - Оптимальная архитектура зависит от баланса точность/размер/время обучения\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09d68e",
   "metadata": {},
   "source": [
    "## 12. Сохранение лучших моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение моделей\n",
    "final_model.save('best_manual_model.h5')\n",
    "tuned_model.save('best_tuned_model.h5')\n",
    "\n",
    "print(\"Модели сохранены:\")\n",
    "print(\"- best_manual_model.h5 (ручной подбор)\")\n",
    "print(\"- best_tuned_model.h5 (Keras Tuner)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
